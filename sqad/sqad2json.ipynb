{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_sentence</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Létající jaguár je novela spisovatele Josefa F...</td>\n",
       "      <td>Kdo je autorem novely Létající jaguár?</td>\n",
       "      <td>Josefa Formánka</td>\n",
       "      <td>Létající jaguár je novela spisovatele Josefa F...</td>\n",
       "      <td>[Létající jaguár je novela spisovatele Josefa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houby (Fungi, dříve Mycophyta) představují vel...</td>\n",
       "      <td>Jak se nazývá věda zabývající se houbami?</td>\n",
       "      <td>mykologie</td>\n",
       "      <td>Věda zabývající se houbami se nazývá mykologie.</td>\n",
       "      <td>[Houby (Fungi, dříve Mycophyta) představují ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Čokoláda je obvyklá součást nejrůznějších druh...</td>\n",
       "      <td>Jak se nazývá strom, jehož zrna jsou využívána...</td>\n",
       "      <td>Theobroma cacao</td>\n",
       "      <td>Čokoláda se vyrábí z kvašených, pražených a ml...</td>\n",
       "      <td>[Čokoláda je obvyklá součást nejrůznějších dru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Václav Havel (5. října 1936 Praha – 18. prosin...</td>\n",
       "      <td>Kdo se stal prvním prezidentem České republiky?</td>\n",
       "      <td>Václav Havel</td>\n",
       "      <td>Václav Havel (5. října 1936 Praha – 18. prosin...</td>\n",
       "      <td>[Václav Havel (5. října 1936 Praha – 18. prosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pampeliška (Taraxacum), či také smetánka, je z...</td>\n",
       "      <td>Do jaké čeledi rostlin patří pampeliška?</td>\n",
       "      <td>hvězdnicovité</td>\n",
       "      <td>Pampeliška (Taraxacum), či také smetánka, je z...</td>\n",
       "      <td>[Pampeliška (Taraxacum), či také smetánka, je ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "1  Létající jaguár je novela spisovatele Josefa F...   \n",
       "2  Houby (Fungi, dříve Mycophyta) představují vel...   \n",
       "3  Čokoláda je obvyklá součást nejrůznějších druh...   \n",
       "4  Václav Havel (5. října 1936 Praha – 18. prosin...   \n",
       "5  Pampeliška (Taraxacum), či také smetánka, je z...   \n",
       "\n",
       "                                            question           answer  \\\n",
       "1             Kdo je autorem novely Létající jaguár?  Josefa Formánka   \n",
       "2          Jak se nazývá věda zabývající se houbami?        mykologie   \n",
       "3  Jak se nazývá strom, jehož zrna jsou využívána...  Theobroma cacao   \n",
       "4    Kdo se stal prvním prezidentem České republiky?     Václav Havel   \n",
       "5           Do jaké čeledi rostlin patří pampeliška?    hvězdnicovité   \n",
       "\n",
       "                                     answer_sentence  \\\n",
       "1  Létající jaguár je novela spisovatele Josefa F...   \n",
       "2    Věda zabývající se houbami se nazývá mykologie.   \n",
       "3  Čokoláda se vyrábí z kvašených, pražených a ml...   \n",
       "4  Václav Havel (5. října 1936 Praha – 18. prosin...   \n",
       "5  Pampeliška (Taraxacum), či také smetánka, je z...   \n",
       "\n",
       "                                           sentences  \n",
       "1  [Létající jaguár je novela spisovatele Josefa ...  \n",
       "2  [Houby (Fungi, dříve Mycophyta) představují ve...  \n",
       "3  [Čokoláda je obvyklá součást nejrůznějších dru...  \n",
       "4  [Václav Havel (5. října 1936 Praha – 18. prosi...  \n",
       "5  [Pampeliška (Taraxacum), či také smetánka, je ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/sqad_split.csv\", index_col=0)\n",
    "df = df.drop(5146)\n",
    "df[\"sentences\"] = df.text.map(lambda x: x.split(\"\\n\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix missmatching answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     8 16\n",
      "   433 16\n",
      "   466 21\n",
      "   600 11\n",
      "   630 41\n",
      "   636 29\n",
      "   652 18\n",
      "   825 19\n",
      "   931 79\n",
      "   953 61\n",
      "   954 61\n",
      "   955 61\n",
      "  1307 29\n",
      "  1972 20\n",
      "  2439 20\n",
      "  2441 20\n",
      "  2702 73\n",
      "  5260 35\n",
      "  6623 144\n",
      "  8264 22\n",
      "  9356 24\n",
      "  9927 62\n",
      " 10026 23\n",
      " 10768 21\n",
      " 11516 28\n",
      " 11525 25\n",
      " 11576 54\n",
      " 11719 38\n",
      " 13341 31\n",
      " 13346 79\n",
      " 13368 50\n",
      " 13444 31\n"
     ]
    }
   ],
   "source": [
    "def get_sentence_index(row):\n",
    "    try:\n",
    "        return row.sentences.index(row.answer_sentence)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "\n",
    "for row in df[df.apply(get_sentence_index, axis=1) == -1].iloc:\n",
    "    try:\n",
    "        anss = row.answer_sentence.split(\"\\n\")\n",
    "        sntcs = row.sentences\n",
    "\n",
    "        i_beg = row.sentences.index(anss[0])\n",
    "        i_end = row.sentences.index(anss[-1])\n",
    "\n",
    "        sentences = sntcs[:i_beg] + [\" \".join(sntcs[i_beg:i_end+1])] + sntcs[i_end+1:]\n",
    "        answer = \" \".join(anss)\n",
    "\n",
    "        df.loc[row.name].sentences = sentences\n",
    "        df.loc[row.name].answer_sentence = answer\n",
    "        print(f\"{row.name: 6d}\", len(answer.split(\" \")))\n",
    "    except ValueError:\n",
    "        print(repr(row.sentences))\n",
    "        print(repr(row.answer_sentence))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if any missmatching answers remain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_sentence</th>\n",
       "      <th>sentences</th>\n",
       "      <th>start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, question, answer, answer_sentence, sentences, start]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts = df.apply(get_sentence_index, axis=1)\n",
    "df[\"start\"] = starts\n",
    "df[starts == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data for chosen task, convert to SQuAD format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, random\n",
    "\n",
    "sentencesep=\" \"\n",
    "\n",
    "\n",
    "def get_context(row, margin=5):\n",
    "    pre = randint(0, margin)\n",
    "    post = randint(margin-pre, 2*margin-pre)\n",
    "    pos = row.start\n",
    "\n",
    "    l = pos-pre\n",
    "    r = pos+post+1\n",
    "    slen = len(row.sentences)\n",
    "\n",
    "    if r - l > slen:\n",
    "        text_sntcs = row.sentences\n",
    "#                 print(slen, text_sntcs)\n",
    "    else:\n",
    "        text_sntcs = []\n",
    "        if l < 0:\n",
    "            text_sntcs += row.sentences[l:]\n",
    "            text_sntcs += row.sentences[:pos]\n",
    "        else:\n",
    "            text_sntcs += row.sentences[l:pos]\n",
    "\n",
    "        if r > slen:\n",
    "            text_sntcs += row.sentences[:r-slen]\n",
    "        text_sntcs += row.sentences[pos:r]\n",
    "\n",
    "        if not r-l == len(text_sntcs):\n",
    "            print(l, pos, r, slen, r-l, len(text_sntcs))\n",
    "            \n",
    "    return text_sntcs\n",
    "\n",
    "\n",
    "def create_training_data(df, task, margin=5, dupe=1.0):\n",
    "    wholecount = 0\n",
    "    index = 0\n",
    "    data = []\n",
    "    out = pd.DataFrame(columns=[\"text\", \"question\", \"answer\", \"answer_sentence\", \"pos\"])\n",
    "    for row in df.iloc:\n",
    "        curdupe = dupe\n",
    "        pars = []\n",
    "        \n",
    "        while random() <= curdupe:\n",
    "            text_sntcs = get_context(row, margin)\n",
    "\n",
    "            answer_start = None\n",
    "            context = f\"{sentencesep} \" + f\" {sentencesep} \".join(text_sntcs) + f\" {sentencesep}\"\n",
    "        \n",
    "            for answer in row.answer.split(\" # \"): # + [row.answer_sentence]:\n",
    "                if answer.lower() in [\"ano\", \"ne\", \"ano.\", \"ne.\"]:\n",
    "                    break\n",
    "                    answer = row.answer_sentence\n",
    "                    wholecount -= 1\n",
    "\n",
    "                m = re.search(re.escape(answer.lower()), context.lower())\n",
    "                if m is None:\n",
    "                    continue\n",
    "#                 if answer == row.answer_sentence:\n",
    "#                     wholecount += 1\n",
    "                answer_start = m.start()\n",
    "                break\n",
    "                \n",
    "            if answer_start is None:\n",
    "                wholecount += 1\n",
    "#                 print(row.question, \"\\n\", answer, \"\\n\", context, \"\\n\")\n",
    "                break\n",
    "    \n",
    "#             print(context.split(\" \")[:3])\n",
    "            if context.split(\" \")[2].lower() == answer.split(\" \")[0]:\n",
    "#                 print(answer)\n",
    "                answer = answer.capitalize()\n",
    "#                 if context.split(\" \")[2] == answer.split(\" \")[0]:\n",
    "#                     print(\"ok\", answer)\n",
    "#                 else:\n",
    "#                     print(\"nok\", answer)\n",
    "            \n",
    "                \n",
    "            \n",
    "            par = {\n",
    "                \"qas\": [{\n",
    "                    \"id\": f\"{row.name}.{len(pars)}\",\n",
    "                    \"question\": row.question,\n",
    "                    \"answers\": [{\n",
    "                        \"text\": answer,\n",
    "                        \"answer_start\": answer_start\n",
    "                    }],\n",
    "                    \"is_impossible\": False\n",
    "                }],\n",
    "                \"context\": context\n",
    "            }\n",
    "            \n",
    "#             if r - l > slen:\n",
    "#                 break\n",
    "        \n",
    "            pars.append(par)\n",
    "            curdupe -= 1\n",
    "        \n",
    "        if pars:\n",
    "            data.append({\"title\": str(row.name), \"paragraphs\": pars})\n",
    "            \n",
    "    print(wholecount, len(data))\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML\n",
    "\n",
    "def highlight_answer(text, answer, start):\n",
    "    text = f\"{text[:start]}>{text[start:]}\"\n",
    "    sub = answer\n",
    "    if sub:\n",
    "        l = text.split(sub)\n",
    "        return f'<span style=\"background-color: #CCCC00\">{sub}</span>'.join(l)\n",
    "    return text.replace(sentencesep, \"<br>\")\n",
    "\n",
    "def view_data(data):\n",
    "    questions = {}\n",
    "    for doc in data:\n",
    "        for par in doc[\"paragraphs\"]:\n",
    "            for qq in par[\"qas\"]:\n",
    "                if not qq[\"answers\"]:\n",
    "                    continue\n",
    "                q = {\n",
    "                    \"question\": qq[\"question\"],\n",
    "                    \"answer\": qq[\"answers\"][0][\"text\"],\n",
    "                    \"start\": qq[\"answers\"][0][\"answer_start\"],\n",
    "                    \"context\": par[\"context\"]\n",
    "                }\n",
    "                questions[qq[\"id\"]] = q\n",
    "    \n",
    "    \n",
    "    keys = list(questions.keys())\n",
    "    slider = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(keys),\n",
    "        step=1,\n",
    "        description='Test:',\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='d'\n",
    "    )\n",
    "\n",
    "    left = widgets.Output(layout={\"width\": \"100%\"})\n",
    "\n",
    "    def f(val):\n",
    "        key = keys[val]\n",
    "        q = questions[key]\n",
    "        \n",
    "        left.clear_output()\n",
    "        with left:\n",
    "            display(HTML(\n",
    "                q[\"question\"] + \"<hr>\" + q[\"answer\"] + \"<hr>\" + highlight_answer(q[\"context\"], q[\"answer\"], q[\"start\"])\n",
    "            ))\n",
    "        \n",
    "        \n",
    "    out = widgets.interactive_output(f, {'val': slider})\n",
    "    display(widgets.VBox([\n",
    "        slider,\n",
    "        widgets.HBox([left])\n",
    "    ]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2309 11163\n"
     ]
    }
   ],
   "source": [
    "data = create_training_data(df, \"answer extraction\", 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade6657f4cb0413b8f24fdab9361af9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=0, continuous_update=False, description='Test:', max=11163), HBox(children=(Out…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def write_squad_json(path, data, version=\"42.0\"):\n",
    "    jj = {\n",
    "        \"version\": version,\n",
    "        \"data\": data\n",
    "    }\n",
    "\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(jj, f)\n",
    "\n",
    "def save_dataset(name):\n",
    "    dev_part = 0.05\n",
    "\n",
    "    trainname = f\"dataset/{name}_train.json\"\n",
    "    devname = f\"dataset/{name}_dev.json\"\n",
    "\n",
    "    random.shuffle(data)\n",
    "    split = int(len(data)*dev_part)\n",
    "    dev = data[:split]\n",
    "    train = data[split:]\n",
    "    print(len(train), len(dev))\n",
    "\n",
    "    write_squad_json(trainname, train)\n",
    "    write_squad_json(devname, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset(\"sqad_extract\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
